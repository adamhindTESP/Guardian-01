Guardian-01

LIGO-Style Gated Development Plan (v0.3 â†’ v1.0)

Purpose:
Transform Guardian-01 from an exploratory prototype into a safety-auditable autonomous system by enforcing explicit gates, entry criteria, and no-go conditions.

No gate may be skipped.
No downstream work is valid unless upstream gates are passed.

â¸»

ğŸ”’ Core Architectural Law (Frozen)

Dual-Veto Rule (Non-Negotiable):
	1.	Semantic / Ethical Veto (Tier-1, Pi)
Deterministic policy gate (benevolence()).
	2.	Physical / Physics Veto (Tier-2, Teensy)
Independent hardware governor with authority over motors and power.

Any design that violates this separation is automatically NO-GO.

This is your equivalent of LIGOâ€™s â€œindependent interferometer arms.â€

â¸»

ğŸ§ª Gate Overview (High Level)

Gate	Name	Purpose	Output
G0	Architecture Freeze	Stop conceptual churn	Frozen interfaces
G1	Simulation Safety	Prove no unsafe plans emerge	Safe logs only
G2	Policy Gate Integrity	Prove Guardian cannot be bypassed	Deterministic veto
G3	Deep Reasoning Validity	Prove LLM degrades safely	Observe / Stop only
G4	Hardware Governor	Prove physics veto works	Motors cut
G5	Integrated Autonomy	End-to-end supervised runs	GO / NO-GO
G6	Field Trial	Limited real-world use	Data only


â¸»

ğŸŸ¢ G0 â€” Architecture Freeze (NOW)

Status: READY TO ENTER
Goal: Stop redesigning and lock vocabulary, roles, and file boundaries.

Entry Criteria
	â€¢	Dual-veto model agreed
	â€¢	Deep reasoning is advisory only
	â€¢	Guardian Seed is semantic, not physical

Exit Artifacts
	â€¢	guardian01_min.py (execution loop)
	â€¢	deep_planner_proxy.py (thinking layer)
	â€¢	Written architecture diagram (ASCII is fine)

NO-GO Conditions
	â€¢	Any claim of â€œprovably benevolentâ€
	â€¢	Any Python component controlling motors directly
	â€¢	Any â€œcomplete systemâ€ language

âœ… You are here. Freeze this.

â¸»

ğŸŸ¢ G1 â€” Simulation Safety Gate

Goal: Prove the system never escalates under uncertainty.

What Is Tested
	â€¢	Random sensor inputs
	â€¢	Missing Ollama
	â€¢	Garbage LLM output
	â€¢	Planner crashes
	â€¢	Empty knowledge base

Pass Criteria
	â€¢	All failures â†’ observe or stop
	â€¢	No movement without explicit approval
	â€¢	No exceptions crash the loop

Required Evidence
	â€¢	Logs from â‰¥1,000 simulated cycles
	â€¢	Zero unsafe actions
	â€¢	Count of fallbacks > risky actions

NO-GO
	â€¢	Random risk
	â€¢	Hard-coded detections
	â€¢	Fake perception

â¸»

ğŸŸ¢ G2 â€” Policy Gate Integrity

Goal: Prove Guardian Seed cannot be lied to.

What Is Tested
	â€¢	Malformed planner outputs
	â€¢	Extreme dignity/risk values
	â€¢	Prompt injection attempts
	â€¢	Adversarial descriptions

Pass Criteria
	â€¢	Guardian vetoes correctly
	â€¢	Inputs are clamped/sanitized
	â€¢	No bypass path exists

Required Evidence
	â€¢	Unit tests for benevolence()
	â€¢	Red-team cases with expected veto

NO-GO
	â€¢	Passing full plan objects
	â€¢	Accepting planner-generated ethics
	â€¢	Silent approval on malformed input

â¸»

ğŸŸ¢ G3 â€” Deep Reasoning Validity

Goal: Ensure â€œthinkingâ€ cannot make things worse.

What Is Tested
	â€¢	Ollama offline
	â€¢	Timeouts
	â€¢	Hallucinated actions
	â€¢	Unsafe CoT reasoning

Pass Criteria
	â€¢	DeepPlannerProxy failure â†’ conservative fallback
	â€¢	LLM never forces motion
	â€¢	Risk always re-computed locally

Required Evidence
	â€¢	Logs showing LLM failure paths
	â€¢	Proof that observe/stop dominates

NO-GO
	â€¢	Trusting LLM risk estimates
	â€¢	Executing multi-step plans blindly
	â€¢	Hidden chain-of-thought assumptions

â¸»

ğŸŸ¢ G4 â€” Physical Governor Gate (Teensy)

Goal: Prove software cannot override physics.

What Is Tested
	â€¢	Overcurrent
	â€¢	Stall
	â€¢	Rapid command spam
	â€¢	Malformed serial input

Pass Criteria
	â€¢	Teensy rejects unsafe commands
	â€¢	Motors cut on fault
	â€¢	Pi cannot override

Required Evidence
	â€¢	Teensy firmware tests
	â€¢	Power cut demonstration

NO-GO
	â€¢	Pi PWM control
	â€¢	Shared safety logic
	â€¢	â€œSoftâ€ motor limits only

â¸»

ğŸŸ¢ G5 â€” Integrated Autonomy (Supervised)

Goal: Validate the full safety funnel.

What Is Tested
	â€¢	Human presence
	â€¢	Obstacles
	â€¢	Long runtimes
	â€¢	Learning persistence

Pass Criteria
	â€¢	All actions pass G1â†’G4
	â€¢	System pauses safely
	â€¢	Logs match expectations

NO-GO
	â€¢	Unexplained movement
	â€¢	Silent veto failures
	â€¢	Operator surprise

â¸»

ğŸŸ¢ G6 â€” Field Trial (Optional, Later)

Goal: Data collection only.

Constraints
	â€¢	Supervised
	â€¢	Kill switch present
	â€¢	No autonomy expansion

â¸»

ğŸ“„ Minimal README.md (Correct, Not Hype)

# Guardian-01

**Status:** Research Prototype  
**Phase:** G0 â†’ G1 (Simulation Safety)

Guardian-01 is an experimental autonomous system exploring how
ethical policy constraints and physical safety governors can be
combined into a robust, auditable control loop.

## Core Principle

No action may occur unless it passes:
1. A deterministic semantic policy gate (Guardian Seed)
2. An independent physical safety governor (Teensy MCU)

## What This Is
- A safety-first control architecture
- A research platform for constrained autonomy
- A system that defaults to stillness under uncertainty

## What This Is NOT
- Not a complete robot
- Not provably benevolent
- Not safe without hardware governor
- Not production-ready

## Current Gate
G0 â€” Architecture Freeze  
Next: G1 â€” Simulation Safety Validation


